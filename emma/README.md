# EMMA - Expert Multimodal & Math Assistant

A production-grade AI system for solving complex mathematical, scientific, and engineering problems using multi-agent orchestration, symbolic computation, and advanced retrieval.

## ğŸš€ Features

- **Multi-Agent Architecture**: Specialized agents for planning, research, math, numeric computation, code execution, and explanation
- **Hybrid Computation**: Integrates Wolfram, MATLAB, SymPy, NumPy, and JAX
- **Advanced RAG**: Vector search with pgvector, knowledge graphs with Neo4j
- **Secure Sandbox**: Docker-based isolated execution environment
- **Production Ready**: Full observability with OpenTelemetry and Langfuse
- **Modern UI**: Next.js 14 with real-time updates and interactive visualizations

## ğŸ“‹ Prerequisites

- Docker & Docker Compose (v2.20+)
- Node.js 18+ (for local development)
- Python 3.11+ (for local development)
- 8GB RAM minimum (16GB recommended)
- 20GB free disk space

## ğŸ› ï¸ Quick Start

### 1. Clone and Setup

```bash
# Clone the repository
git clone <repository-url> emma
cd emma

# Copy environment variables
cp .env.example .env

# Edit .env with your API keys (OpenAI, Wolfram, etc.)
nano .env
```

### 2. Start with Docker Compose

```bash
# Start all services in development mode
docker compose -f infra/compose/docker-compose.dev.yml up --build

# Or run in background
docker compose -f infra/compose/docker-compose.dev.yml up -d --build
```

This will start:
- **Web UI**: http://localhost:3000
- **API**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs
- **MinIO Console**: http://localhost:9001 (minioadmin/minioadmin)
- **Neo4j Browser**: http://localhost:7474 (neo4j/neo4j_password)

### 3. Initialize Database

```bash
# Run migrations
docker compose -f infra/compose/docker-compose.dev.yml exec api \
  alembic upgrade head

# Load demo corpus (optional)
docker compose -f infra/compose/docker-compose.dev.yml exec api \
  python scripts/load_demo_corpus.py
```

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Next.js   â”‚â”€â”€â”€â”€â–¶â”‚   FastAPI   â”‚â”€â”€â”€â”€â–¶â”‚  LangGraph  â”‚
â”‚     Web     â”‚     â”‚   Gateway   â”‚     â”‚ Orchestratorâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
                    â”‚                 â”‚   â”‚             â”‚
              â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â–¼â”€â”    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
              â”‚PostgreSQL â”‚    â”‚   Redis    â”‚    â”‚   Neo4j   â”‚
              â”‚ pgvector  â”‚    â”‚   Queue    â”‚    â”‚    KG     â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚                    â”‚
                      â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
                      â”‚  Workers  â”‚       â”‚  Sandbox  â”‚
                      â”‚ Dramatiq  â”‚       â”‚   Docker  â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
emma/
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ api/              # FastAPI backend
â”‚   â”œâ”€â”€ workers/          # Background job processors
â”‚   â””â”€â”€ web/              # Next.js frontend
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ emma_core/        # Shared Python libraries
â”‚   â”œâ”€â”€ emma_prompts/     # System prompts
â”‚   â””â”€â”€ emma_ui/          # Shared UI components
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ retriever/        # RAG pipeline
â”‚   â”œâ”€â”€ sandbox/          # Code execution sandbox
â”‚   â”œâ”€â”€ compute_bridge/   # Math engine adapters
â”‚   â””â”€â”€ kg/               # Knowledge graph operations
â”œâ”€â”€ infra/
â”‚   â”œâ”€â”€ docker/           # Dockerfiles
â”‚   â”œâ”€â”€ compose/          # Docker Compose configs
â”‚   â”œâ”€â”€ k8s/              # Kubernetes manifests
â”‚   â””â”€â”€ db/               # Database migrations
â””â”€â”€ tests/
    â”œâ”€â”€ api/              # API tests
    â”œâ”€â”€ e2e/              # End-to-end tests
    â””â”€â”€ eval/             # Evaluation suites
```

## ğŸ”§ Configuration

### Environment Variables

Key environment variables in `.env`:

```bash
# LLM Provider
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4-turbo-preview

# Compute Engines
WOLFRAM_MODE=cloud  # cloud, alpha, off
WOLFRAM_APP_ID=...
MATLAB_MODE=off     # engine, mps, off

# Features
ENABLE_WEB_SEARCH=true
ENABLE_CODE_EXECUTION=true
SANDBOX_TIMEOUT_SECONDS=30
```

### Compute Bridge Modes

- **Wolfram**: Set `WOLFRAM_MODE=cloud` and provide `WOLFRAM_APP_ID`
- **MATLAB**: Set `MATLAB_MODE=engine` and ensure MATLAB is installed
- **Fallback**: Always uses SymPy/NumPy when external engines are unavailable

## ğŸ§ª Testing

```bash
# Run unit tests
docker compose -f infra/compose/docker-compose.dev.yml exec api \
  pytest tests/api -v

# Run evaluation suite
docker compose -f infra/compose/docker-compose.dev.yml exec api \
  python scripts/run_eval.py --suite gsm8k

# Run E2E tests
npm run test:e2e --prefix apps/web
```

## ğŸ“Š API Usage

### Solve a Problem

```bash
curl -X POST http://localhost:8000/v1/chat/solve \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -d '{
    "question": "Solve x^2 + 5x + 6 = 0",
    "need_steps": true,
    "preferred_units": "SI"
  }'
```

### Upload Documents

```bash
curl -X POST http://localhost:8000/v1/ingest/docs \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -F "files=@paper.pdf" \
  -F "files=@notes.md"
```

### Get Execution Trace

```bash
curl http://localhost:8000/v1/trace/{run_id} \
  -H "Authorization: Bearer YOUR_TOKEN"
```

## ğŸš¢ Production Deployment

### Using Docker Compose

```bash
# Use production compose file
docker compose -f infra/compose/docker-compose.prod.yml up -d
```

### Using Kubernetes

```bash
# Apply Kubernetes manifests
kubectl apply -f infra/k8s/

# Or use Helm
helm install emma infra/k8s/helm-chart/
```

### Environment-Specific Settings

For production:
1. Set strong passwords in `.env`
2. Enable TLS/SSL
3. Configure proper CORS origins
4. Set up monitoring (Prometheus/Grafana)
5. Configure backup strategies

## ğŸ” Monitoring

- **Traces**: View in Langfuse dashboard
- **Metrics**: OpenTelemetry exports to configured endpoint
- **Logs**: Structured JSON logs to stdout
- **Health**: GET `/v1/health` endpoint

## ğŸ›¡ï¸ Security

- JWT-based authentication
- Rate limiting per user
- Sandboxed code execution
- Input validation and sanitization
- Secrets management via environment variables
- Content filtering for prompt injection

## ğŸ“š Documentation

- **API Docs**: http://localhost:8000/docs
- **Architecture**: See `/docs/architecture.md`
- **Development**: See `/docs/development.md`
- **Deployment**: See `/docs/deployment.md`

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run tests
5. Submit a pull request

## ğŸ“„ License

MIT License - see LICENSE file for details

## ğŸ†˜ Support

- **Issues**: GitHub Issues
- **Discussions**: GitHub Discussions
- **Email**: support@emma-ai.com

## ğŸ¯ Roadmap

- [ ] Multi-modal input (images, handwriting)
- [ ] Collaborative problem solving
- [ ] Custom tool creation interface
- [ ] Mobile applications
- [ ] Plugin marketplace
- [ ] Advanced visualization tools

---

Built with â¤ï¸ by the EMMA Team